export default {
  template:
    'apiVersion: tekton.dev/v1beta1\nkind: PipelineRun\nmetadata:\n  name: dedup-ray-pipeline\n  annotations:\n    tekton.dev/output_artifacts: \'{"wow-so-cool": [{"key":\n      "artifacts/$PIPELINERUN/wow-so-cool/Output.tgz", "name":\n      "wow-so-cool-Output", "path": "/tmp/outputs/Output/data"}],\n      "ok-great": [{"key":\n      "artifacts/$PIPELINERUN/ok-great/Output.tgz", "name":\n      "ok-great-Output", "path": "/tmp/outputs/Output/data"}]}\'\n    tekton.dev/input_artifacts: \'{"execute-ray-jobs": [{"name":\n      "wow-so-cool-Output", "parent_task":\n      "wow-so-cool"}, {"name": "ok-great-Output",\n      "parent_task": "ok-great"}]}\'\n    tekton.dev/artifact_bucket: mlpipeline\n    tekton.dev/artifact_endpoint: minio-service.kubeflow:9000\n    tekton.dev/artifact_endpoint_scheme: http://\n    tekton.dev/artifact_items: \'{"cleanup-ray-cluster": [],\n      "wow-so-cool": [["Output", "$(results.Output.path)"]],\n      "execute-ray-jobs": [], "ok-great": [["Output",\n      "$(results.Output.path)"]]}\'\n    sidecar.istio.io/inject: "false"\n    tekton.dev/template: ""\n    pipelines.kubeflow.org/big_data_passing_format: $(workspaces.$TASK_NAME.path)/artifacts/$ORIG_PR_NAME/$TASKRUN_NAME/$TASK_PARAM_NAME\n    pipelines.kubeflow.org/pipeline_spec: \'{"description": "Pipeline to show how to\n      use codeflare sdk to create Ray cluster and run dedup", "inputs":\n      [{"default": "kfp-ray-dedup", "name": "name", "optional": true, "type":\n      "String"}, {"default": "8", "name": "num_workers", "optional": true,\n      "type": "String"}, {"default": "8", "name": "worker_cpu", "optional":\n      true, "type": "String"}, {"default": "32", "name": "worker_memory",\n      "optional": true, "type": "String"}, {"default": "0", "name":\n      "worker_gpu", "optional": true, "type": "String"}, {"default": "1",\n      "name": "wait_ready_tmout", "optional": true, "type": "String"},\n      {"default": "100", "name": "wait_ready_retries", "optional": true, "type":\n      "String"}, {"default": "1", "name": "print_tmout", "optional": true,\n      "type": "String"}, {"default": "ray-dedup-template", "name":\n      "template_cm", "optional": true, "type": "String"}, {"default":\n      "quay.io/ibmdpdev/dedup-exact-ray:2.5.1-py310", "name": "image",\n      "optional": true, "type": "String"}, {"default":\n      "cos-optimal-llm-pile/blue-pile/0_internet/2_commoncrawl/ete=v0.2",\n      "name": "input_path", "optional": true, "type": "String"}, {"default":\n      "cos-optimal-llm-pile/boris_test/", "name": "output_path", "optional":\n      true, "type": "String"}, {"default": "contents", "name": "content",\n      "optional": true, "type": "String"}, {"default": "100", "name":\n      "max_files", "optional": true, "type": "String"}, {"default": "5", "name":\n      "n_sample", "optional": true, "type": "String"}, {"default": ".75",\n      "name": "processor_cpu", "optional": true, "type": "String"}, {"default":\n      ".5", "name": "hash_cpu", "optional": true, "type": "String"}], "name":\n      "dedup-ray-pipeline"}\'\n  labels:\n    pipelines.kubeflow.org/pipelinename: ""\n    pipelines.kubeflow.org/generation: ""\nspec:\n  params:\n    - name: content\n      value: contents\n    - name: hash_cpu\n      value: ".5"\n    - name: image\n      value: quay.io/ibmdpdev/dedup-exact-ray:2.5.1-py310\n    - name: input_path\n      value: cos-optimal-llm-pile/blue-pile/0_internet/2_commoncrawl/ete=v0.2\n    - name: max_files\n      value: "100"\n    - name: n_sample\n      value: "5"\n    - name: name\n      value: kfp-ray-dedup\n    - name: num_workers\n      value: "8"\n    - name: output_path\n      value: cos-optimal-llm-pile/boris_test/\n    - name: print_tmout\n      value: "1"\n    - name: processor_cpu\n      value: ".75"\n    - name: template_cm\n      value: ray-dedup-template\n    - name: wait_ready_retries\n      value: "100"\n    - name: wait_ready_tmout\n      value: "1"\n    - name: worker_cpu\n      value: "8"\n    - name: worker_gpu\n      value: "0"\n    - name: worker_memory\n      value: "32"\n  pipelineSpec:\n    params:\n      - name: content\n        default: contents\n      - name: hash_cpu\n        default: ".5"\n      - name: image\n        default: quay.io/ibmdpdev/dedup-exact-ray:2.5.1-py310\n      - name: input_path\n        default: cos-optimal-llm-pile/blue-pile/0_internet/2_commoncrawl/ete=v0.2\n      - name: max_files\n        default: "100"\n      - name: n_sample\n        default: "5"\n      - name: name\n        default: kfp-ray-dedup\n      - name: num_workers\n        default: "8"\n      - name: output_path\n        default: cos-optimal-llm-pile/boris_test/\n      - name: print_tmout\n        default: "1"\n      - name: processor_cpu\n        default: ".75"\n      - name: template_cm\n        default: ray-dedup-template\n      - name: wait_ready_retries\n        default: "100"\n      - name: wait_ready_tmout\n        default: "1"\n      - name: worker_cpu\n        default: "8"\n      - name: worker_gpu\n        default: "0"\n      - name: worker_memory\n        default: "32"\n    tasks:\n      - name: wow-so-cool\n        params:\n          - name: content\n            value: $(params.content)\n          - name: hash_cpu\n            value: $(params.hash_cpu)\n          - name: input_path\n            value: $(params.input_path)\n          - name: max_files\n            value: $(params.max_files)\n          - name: n_sample\n            value: $(params.n_sample)\n          - name: num_workers\n            value: $(params.num_workers)\n          - name: processor_cpu\n            value: $(params.processor_cpu)\n          - name: worker_cpu\n            value: $(params.worker_cpu)\n          - name: worker_memory\n            value: $(params.worker_memory)\n        taskSpec:\n          steps:\n            - name: main\n              args:\n                - --num-workers\n                - $(inputs.params.num_workers)\n                - --worker-cpu\n                - $(inputs.params.worker_cpu)\n                - --worker-memory\n                - $(inputs.params.worker_memory)\n                - --input-path\n                - $(inputs.params.input_path)\n                - --content\n                - $(inputs.params.content)\n                - --n-sample\n                - $(inputs.params.n_sample)\n                - --max-files\n                - $(inputs.params.max_files)\n                - --processor-cpu\n                - $(inputs.params.processor_cpu)\n                - --hash-cpu\n                - $(inputs.params.hash_cpu)\n                - ----output-paths\n                - $(results.Output.path)\n              command:\n                - sh\n                - -ec\n                - |\n                  program_path=$(mktemp)\n                  printf "%s" "$0" \u003e "$program_path"\n                  python3 -u "$program_path" "$@"\n                - \u003e\n                  def compute_execution_params(num_workers,  # number of workers\n                                               worker_cpu,  # number cpus per worker\n                                               worker_memory,  # memory per worker\n                                               # Dedup specific parameters\n                                               input_path,  # data input directory\n                                               content,  # name of the documents column\n                                               n_sample,  # number of tables to sample\n                                               max_files,  # maximum amount of files to process\n                                               processor_cpu,  # Number of CPUs to do table processing\n                                               hash_cpu  # Number of CPUs to do table processing\n                                               ):\n                      # required import\n                      from pyarrow import fs\n                      import pyarrow.parquet as pq\n\n                      import random\n                      import sys\n                      import math\n                      import json\n                      import os\n\n                      COS_URL = "https://s3.us-east.cloud-object-storage.appdomain.cloud"\n                      EXECUTION_OF_KB_DOC = 0.00025\n                      GB = 1024*1024*1024\n\n                      def _credentials():\n                          cos_key = os.getenv(\'COS_KEY\', "")\n                          cos_secret = os.getenv(\'COS_SECRET\', "")\n                          if cos_key == "" or cos_secret == "":\n                              print("Failed to get cos credentials")\n                              sys.exit(1)\n                          return cos_key, cos_secret\n\n                      def _sample_table_data(cos_key, cos_secret, input_path, max_files, n_samples):\n\n                          # Create fs\n                          s3 = fs.S3FileSystem(access_key=cos_key, secret_key=cos_secret, request_timeout=20, connect_timeout=20,\n                                               retry_strategy=fs.AwsStandardS3RetryStrategy(max_attempts=20),\n                                               endpoint_override=COS_URL)\n                          # Get files list\n                          path_list = [file.path for\n                                       file in s3.get_file_info(fs.FileSelector(input_path)) if file.path.endswith(".parquet")]\n                          # Cap the amount of files if required\n                          if max_files \u003e 0:\n                              cap = min(len(path_list), max_files)\n                              path_list = path_list[:cap]\n                          print(f"Number of s3 files is {len(path_list)}")\n\n                          # Pick files to sample\n                          if len(path_list) \u003e n_samples:\n                              # Pick files at random\n                              files = [int(random.random()*len(path_list)) for _ in range(n_samples)]\n                          else:\n                              # use all existing files\n                              files = range(len(path_list))\n                          print(f"Using files {files} to sample data")\n\n                          # Read table and compute number of docs and sizes\n                          number_of_docs = []\n                          table_sizes = []\n                          for f in files:\n                              f_name = path_list[f]\n                              table = pq.read_table(f_name, filesystem=s3, columns=[content])\n                              number_of_docs.append(table.num_rows)\n                              table_sizes.append(sys.getsizeof(table))\n\n                          # compute averages\n                          av_number_docs = sum(number_of_docs) / len(files)\n                          av_table_size = sum(table_sizes) / len(files) / GB\n                          av_doc_size = av_table_size * GB / av_number_docs / 1024\n                          print(f"average number of docs {av_number_docs}, average table size {av_table_size} GB, "\n                                f"average doc size {av_doc_size} kB")\n\n                          # compute number of docs\n                          number_of_docs = av_number_docs * len(path_list)\n                          print(f"Estimated number of docs {number_of_docs}")\n                          return av_table_size, av_doc_size, number_of_docs\n\n                      # get credentials\n                      cos_key, cos_secret = _credentials()\n\n                      # sample input data\n                      av_table_size, av_doc_size, number_of_docs = _sample_table_data(\n                          cos_key=cos_key, cos_secret=cos_secret, input_path=input_path, max_files=int(max_files),\n                          n_samples=int(n_sample))\n                      n_hashes = math.ceil(number_of_docs * 32 / GB)\n                      print(f"Estimated Required hashes {n_hashes}")\n\n                      # Validate cluster size\n                      cluster_cpu = int(num_workers) * int(worker_cpu) * .85\n                      cluster_mem = int(num_workers) * int(worker_memory) * .85\n                      required_hash_cpu = n_hashes * float(hash_cpu)\n                      required_hash_mem = n_hashes * 2\n                      if required_hash_cpu \u003e cluster_cpu or required_hash_mem \u003e cluster_mem:\n                          print(f"Cluster is too small - hashes required cpus {required_hash_cpu}; "\n                                f"hashes required memory {required_hash_mem}")\n                          sys.exit(1)\n                      # Define number of workers\n                      n_workers = int((cluster_cpu - required_hash_cpu)/float(processor_cpu))\n                      print(f"Number of workers - {n_workers}")\n                      if n_workers \u003c 5:\n                          print(f"Cluster is too small - estimated number of workers {n_workers}")\n                          sys.exit(1)\n                      r_mem = required_hash_mem * 2 + av_table_size * 4 * n_workers\n                      print(f"Required execution memory {r_mem} GB")\n                      if r_mem \u003e cluster_mem:\n                          print(f"Not enough memory to run de duping, required {r_mem}, available {cluster_mem}")\n                          print(f"Try to increase the size of the cluster or increase size of the cpu per worker")\n                          sys.exit(1)\n                      print(f"Projected execution time {EXECUTION_OF_KB_DOC * av_doc_size * number_of_docs / n_workers / 60} min")\n                      return json.dumps({\'workers\': n_workers, \'hashes\': n_hashes})\n\n                  def _serialize_str(str_value: str) -\u003e str:\n                      if not isinstance(str_value, str):\n                          raise TypeError(\'Value "{}" has type "{}" instead of str.\'.format(\n                              str(str_value), str(type(str_value))))\n                      return str_value\n\n                  import argparse\n\n                  _parser = argparse.ArgumentParser(prog=\'Compute execution params\', description=\'\')\n\n                  _parser.add_argument("--num-workers", dest="num_workers", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--worker-cpu", dest="worker_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--worker-memory", dest="worker_memory", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--input-path", dest="input_path", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--content", dest="content", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--n-sample", dest="n_sample", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--max-files", dest="max_files", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--processor-cpu", dest="processor_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--hash-cpu", dest="hash_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)\n\n                  _parsed_args = vars(_parser.parse_args())\n\n                  _output_files = _parsed_args.pop("_output_paths", [])\n\n\n                  _outputs = compute_execution_params(**_parsed_args)\n\n\n                  _outputs = [_outputs]\n\n\n                  _output_serializers = [\n                      _serialize_str,\n\n                  ]\n\n\n                  import os\n\n                  for idx, output_file in enumerate(_output_files):\n                      try:\n                          os.makedirs(os.path.dirname(output_file))\n                      except OSError:\n                          pass\n                      with open(output_file, \'w\') as f:\n                          f.write(_output_serializers[idx](_outputs[idx]))\n              env:\n                - name: COS_KEY\n                  valueFrom:\n                    secretKeyRef:\n                      key: cos-key\n                      name: cos-access\n                - name: COS_SECRET\n                  valueFrom:\n                    secretKeyRef:\n                      key: cos-secret\n                      name: cos-access\n              image: quay.io/ibmdpdev/kfp-oc:2.5.1-py310\n              imagePullPolicy: Always\n          params:\n            - name: content\n            - name: hash_cpu\n            - name: input_path\n            - name: max_files\n            - name: n_sample\n            - name: num_workers\n            - name: processor_cpu\n            - name: worker_cpu\n            - name: worker_memory\n          results:\n            - name: Output\n              type: string\n              description: /tmp/outputs/Output/data\n          metadata:\n            labels:\n              pipelines.kubeflow.org/cache_enabled: "true"\n            annotations:\n              pipelines.kubeflow.org/component_spec_digest: \'{"name": "Compute execution\n                params", "outputs": [{"name": "Output", "type": "String"}],\n                "version": "Compute execution\n                params@sha256=441f924ac97baa98300019ea5bc3a1fb109d4c2f80de356fde7984b9505e1c98"}\'\n      - name: ok-great\n        params:\n          - name: image\n            value: $(params.image)\n          - name: name\n            value: $(params.name)\n          - name: num_workers\n            value: $(params.num_workers)\n          - name: template_cm\n            value: $(params.template_cm)\n          - name: worker_cpu\n            value: $(params.worker_cpu)\n          - name: worker_gpu\n            value: $(params.worker_gpu)\n          - name: worker_memory\n            value: $(params.worker_memory)\n        taskSpec:\n          steps:\n            - name: main\n              args:\n                - --name\n                - $(inputs.params.name)\n                - --num-workers\n                - $(inputs.params.num_workers)\n                - --worker-cpu\n                - $(inputs.params.worker_cpu)\n                - --worker-memory\n                - $(inputs.params.worker_memory)\n                - --worker-gpu\n                - $(inputs.params.worker_gpu)\n                - --image\n                - $(inputs.params.image)\n                - ----output-paths\n                - $(results.Output.path)\n              command:\n                - sh\n                - -ec\n                - |\n                  program_path=$(mktemp)\n                  printf "%s" "$0" \u003e "$program_path"\n                  python3 -u "$program_path" "$@"\n                - \u003e\n                  def start_ray_cluster(\n                          name,          # name of Ray cluster\n                          num_workers,   # number of workers\n                          worker_cpu,    # number cpus per worker\n                          worker_memory, # memory per worker\n                          worker_gpu,    # number of gpus per worker\n                          image,         # image for Ray cluster\n                  ):\n                      # Imports\n                      import os\n                      import sys\n                      import time\n\n                      import ray\n                      from codeflare_sdk.cluster.auth import TokenAuthentication\n                      from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n\n                      # Ray routine to get the amount of nodes\n                      @ray.remote\n                      def get_cluster_nodes():\n                          nodes = ray.nodes()\n                          nnodes = -1\n                          for n in nodes:\n                              if n["alive"]:\n                                  nnodes = nnodes + 1\n                          return nnodes\n\n                      # get current namespace\n                      ns = os.getenv("NAMESPACE", "default")\n                      # change the current directory to ensure that we can write\n                      os.chdir("/tmp")\n                      print(f"Executing in namespace {ns}, current working directory is {os.getcwd()}")\n\n                      # Create authentication object for oc user permissions\n                      with open("/var/run/secrets/kubernetes.io/serviceaccount/token", "r") as file:\n                          token = file.read().rstrip()\n                      auth = TokenAuthentication(token=token, server="https://kubernetes.default:443", skip_tls=True)\n                      try:\n                          auth.login()\n                      except Exception as e:\n                          print(f"Failed to log into openshift cluster, error {e}. Please check token/server values provided")\n                          sys.exit(1)\n                      print("successfully logged in")\n\n                      # Create and configure our cluster object (and appwrapper)\n                      cluster = Cluster(\n                          ClusterConfiguration(\n                              name=name,\n                              namespace=ns,\n                              min_worker=int(num_workers),\n                              max_worker=int(num_workers),\n                              min_cpus=int(worker_cpu),\n                              max_cpus=int(worker_cpu),\n                              min_memory=int(worker_memory),\n                              max_memory=int(worker_memory),\n                              gpu=int(worker_gpu),\n                              image=image,\n                              template="/templates/ray_template.yaml",\n                              instascale=False,\n                          )\n                      )\n                      print(f"Configuration for Ray cluster {name} in namespace {ns} is created")\n\n                      try:\n                          # bring up the cluster\n                          cluster.up()\n                          print(f"Creating Ray cluster {name} in namespace {ns}...")\n\n                          # and wait for it being up\n                          cluster.wait_ready()\n                          rc = cluster.details(print_to_console=False)\n                          print("Ray cluster is ready")\n                          print(rc)\n\n                          # Get cluster connection point for job submission\n                          ray_dashboard_uri = cluster.cluster_dashboard_uri()\n                          ray_cluster_uri = cluster.cluster_uri()\n                          print(f"Ray_cluster is at {ray_cluster_uri}")\n                          print(f"Ray_cluster dashboard is at {ray_dashboard_uri}")\n\n                          # wait to ensure that cluster is really up. Without this we can get occasional 503 error\n                          time.sleep(5)\n\n                          # make sure all the nodes are up\n                          ray.init(address=f"{ray_cluster_uri}")\n                          running = 0\n                          while running \u003c int(num_workers):\n                              running = ray.get(get_cluster_nodes.remote())\n                              print(f"{running} nodes are currently available")\n                              time.sleep(1)\n                          ray.shutdown()\n                          return ray_dashboard_uri\n                      except Exception as e:\n                          print(f"Failed to init Ray cluster, error {e}")\n                          sys.exit(1)\n\n                  def _serialize_str(str_value: str) -\u003e str:\n                      if not isinstance(str_value, str):\n                          raise TypeError(\'Value "{}" has type "{}" instead of str.\'.format(\n                              str(str_value), str(type(str_value))))\n                      return str_value\n\n                  import argparse\n\n                  _parser = argparse.ArgumentParser(prog=\'Start ray cluster\', description=\'\')\n\n                  _parser.add_argument("--name", dest="name", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--num-workers", dest="num_workers", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--worker-cpu", dest="worker_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--worker-memory", dest="worker_memory", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--worker-gpu", dest="worker_gpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--image", dest="image", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)\n\n                  _parsed_args = vars(_parser.parse_args())\n\n                  _output_files = _parsed_args.pop("_output_paths", [])\n\n\n                  _outputs = start_ray_cluster(**_parsed_args)\n\n\n                  _outputs = [_outputs]\n\n\n                  _output_serializers = [\n                      _serialize_str,\n\n                  ]\n\n\n                  import os\n\n                  for idx, output_file in enumerate(_output_files):\n                      try:\n                          os.makedirs(os.path.dirname(output_file))\n                      except OSError:\n                          pass\n                      with open(output_file, \'w\') as f:\n                          f.write(_output_serializers[idx](_outputs[idx]))\n              env:\n                - name: NAMESPACE\n                  valueFrom:\n                    fieldRef:\n                      fieldPath: metadata.namespace\n              image: quay.io/ibmdpdev/kfp-oc:2.5.1-py310\n              imagePullPolicy: Always\n              volumeMounts:\n                - mountPath: /templates\n                  name: templates\n          params:\n            - name: image\n            - name: name\n            - name: num_workers\n            - name: template_cm\n            - name: worker_cpu\n            - name: worker_gpu\n            - name: worker_memory\n          results:\n            - name: Output\n              type: string\n              description: /tmp/outputs/Output/data\n          volumes:\n            - configMap:\n                name: $(inputs.params.template_cm)\n              name: templates\n          metadata:\n            labels:\n              pipelines.kubeflow.org/cache_enabled: "true"\n            annotations:\n              pipelines.kubeflow.org/component_spec_digest: \'{"name": "Start ray cluster",\n                "outputs": [{"name": "Output", "type": "String"}], "version":\n                "Start ray\n                cluster@sha256=aa5e200274d1b535332c459aaa022a0209f81336c1ea303b319be92deb2b9347"}\'\n              pipelines.kubeflow.org/max_cache_staleness: P0D\n        runAfter:\n          - wow-so-cool\n      - name: execute-ray-jobs\n        params:\n          - name: wow-so-cool-Output\n            value: $(tasks.wow-so-cool.results.Output)\n          - name: content\n            value: $(params.content)\n          - name: hash_cpu\n            value: $(params.hash_cpu)\n          - name: input_path\n            value: $(params.input_path)\n          - name: max_files\n            value: $(params.max_files)\n          - name: output_path\n            value: $(params.output_path)\n          - name: print_tmout\n            value: $(params.print_tmout)\n          - name: processor_cpu\n            value: $(params.processor_cpu)\n          - name: ok-great-Output\n            value: $(tasks.ok-great.results.Output)\n          - name: wait_ready_retries\n            value: $(params.wait_ready_retries)\n          - name: wait_ready_tmout\n            value: $(params.wait_ready_tmout)\n        taskSpec:\n          steps:\n            - name: main\n              args:\n                - --ray-dashboard-uri\n                - $(inputs.params.ok-great-Output)\n                - --wait-ready-tmout\n                - $(inputs.params.wait_ready_tmout)\n                - --wait-ready-retries\n                - $(inputs.params.wait_ready_retries)\n                - --print-tmout\n                - $(inputs.params.print_tmout)\n                - --input-path\n                - $(inputs.params.input_path)\n                - --output-path\n                - $(inputs.params.output_path)\n                - --content\n                - $(inputs.params.content)\n                - --max-files\n                - $(inputs.params.max_files)\n                - --processor-cpu\n                - $(inputs.params.processor_cpu)\n                - --hash-cpu\n                - $(inputs.params.hash_cpu)\n                - --execution-params\n                - $(inputs.params.wow-so-cool-Output)\n              command:\n                - sh\n                - -ec\n                - |\n                  program_path=$(mktemp)\n                  printf "%s" "$0" \u003e "$program_path"\n                  python3 -u "$program_path" "$@"\n                - \u003e\n                  def execute_ray_jobs(\n                          ray_dashboard_uri, # ray dashboard uri\n                          wait_ready_tmout,  # wait tmout for job ready\n                          wait_ready_retries,# wait retries for job ready\n                          print_tmout,       # print timeout\n                          # Dedup specific parameters\n                          input_path,        # data input directory\n                          output_path,       # data output directory\n                          content,           # name of the documents column\n                          max_files,         # maximum amount of files to process\n                          processor_cpu,     # Number of CPUs to do table processing\n                          hash_cpu,          # Number of CPUs to do table processing\n                          execution_params   # config parameters computed in initial step\n                  ):\n                      # required imports\n                      from pyarrow import fs\n                      import json\n                      import sys\n                      import time\n                      import os\n\n                      import requests\n                      from ray.job_submission import JobStatus\n\n                      COS_URL = "https://s3.us-east.cloud-object-storage.appdomain.cloud"\n\n                      # Get credentials\n                      def _credentials():\n                          cos_key = os.getenv(\'COS_KEY\', "")\n                          cos_secret = os.getenv(\'COS_SECRET\', "")\n                          if cos_key == "" or cos_secret == "":\n                              print("Failed to get cos credentials")\n                              sys.exit(1)\n                          return cos_key, cos_secret\n\n                      # Get job status\n                      def _get_job_status(ray_dashboard_uri, job_id):\n                          resp = requests.get(f"{ray_dashboard_uri}/api/jobs/{job_id}")\n                          if resp.status_code == 200:\n                              rst = json.loads(resp.text)\n                              return rst["status"]\n                          else:\n                              print(f"Getting job execution status failed, code {resp.status_code}")\n                              return JobStatus.PENDING\n\n                      # Get job log\n                      def _get_job_log(ray_dashboard_uri, job_id):\n                          resp = requests.get(f"{ray_dashboard_uri}/api/jobs/{job_id}/logs")\n                          if resp.status_code == 200:\n                              rst = json.loads(resp.text)\n                              return rst["logs"]\n                          else:\n                              print(f"Getting job execution log failed, code {resp.status_code}")\n                              return \'\'\n\n                      # Print job log\n                      def _print_log(log, previous_log_len):\n                          l_to_print = log[previous_log_len:]\n                          if len(l_to_print) \u003e 0:\n                              print(log)\n\n                      # Get parameters necessary for submitting\n                      execution_params = json.loads(execution_params)\n                      cos_key, cos_secret = _credentials()\n\n                      #Submitting job\n                      job_id = None\n                      try:\n                          resp = requests.post(\n                              f"{ray_dashboard_uri}/api/jobs/",\n                              json={\n                                  "entrypoint": f"python dedup_exact_files_wf.py --input_path={input_path} --output_path={output_path} "\n                                                f"--content={content} --max_files={int(max_files)} --worker_cpu={float(processor_cpu)} "\n                                                f"--hash_cpu={float(hash_cpu)} --num_hashes={execution_params[\'hashes\']} "\n                                                f"--num_workers={execution_params[\'workers\']}",\n                                  "runtime_env": {\'env_vars\': {\'COS_KEY\': cos_key, \'COS_SECRET\': cos_secret}}\n                              }\n                          )\n                          if resp.status_code == 200:\n                              rst = json.loads(resp.text)\n                              job_id = rst["job_id"]\n                              print(f"Submitted job to Ray with the id: {job_id}")\n                          else:\n                              print(f"Failed to submitted job to Ray, code : {resp.status_code}")\n\n                      except Exception as e:\n                          print(f"Failed to submit job to Ray cluster, error {e}")\n                          sys.exit(1)\n\n                      # Waiting job to start\n                      status = JobStatus.PENDING\n                      tries = 0\n                      try:\n                          while status != JobStatus.RUNNING:\n                              tries = tries + 1\n                              status = _get_job_status(ray_dashboard_uri, job_id)\n                              if status in {JobStatus.STOPPED, JobStatus.SUCCEEDED, JobStatus.FAILED}:\n                                  break\n                              if tries \u003e= int(wait_ready_retries):\n                                  print(f"Failed to get job success status in {int(wait_ready_retries)} tries")\n                                  sys.exit(1)\n                              time.sleep(int(wait_ready_tmout))\n                          print(f"Job execution status is {status}")\n\n                          # while job is running get job\'s log\n                          previous_log_len = 0\n                          while status == JobStatus.RUNNING:\n                              log = _get_job_log(ray_dashboard_uri, job_id)\n                              _print_log(log, previous_log_len)\n                              previous_log_len = len(log)\n                              time.sleep(int(print_tmout))\n                              # Update status\n                              status = _get_job_status(ray_dashboard_uri, job_id)\n\n                          # print final log and status\n                          flog = _get_job_log(ray_dashboard_uri, job_id)\n                          _print_log(flog, previous_log_len)\n                          print(f"Job execution status is {status}")\n\n                          # Save the log to S3\n                          s3 = fs.S3FileSystem(access_key=cos_key, secret_key=cos_secret, request_timeout=20, connect_timeout=20,\n                                               retry_strategy=fs.AwsStandardS3RetryStrategy(max_attempts=20),endpoint_override=COS_URL)\n                          with s3.open_output_stream(f"{output_path}execution.log") as stream:\n                              stream.write(bytes(flog, \'UTF-8\'))\n\n                      except Exception as e:\n                          print(f"Failed to get Ray job execution result, error {e}")\n                          sys.exit(1)\n\n                  import argparse\n\n                  _parser = argparse.ArgumentParser(prog=\'Execute ray jobs\', description=\'\')\n\n                  _parser.add_argument("--ray-dashboard-uri", dest="ray_dashboard_uri", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--wait-ready-tmout", dest="wait_ready_tmout", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--wait-ready-retries", dest="wait_ready_retries", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--print-tmout", dest="print_tmout", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--input-path", dest="input_path", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--output-path", dest="output_path", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--content", dest="content", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--max-files", dest="max_files", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--processor-cpu", dest="processor_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--hash-cpu", dest="hash_cpu", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parser.add_argument("--execution-params", dest="execution_params", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parsed_args = vars(_parser.parse_args())\n\n\n                  _outputs = execute_ray_jobs(**_parsed_args)\n              env:\n                - name: COS_KEY\n                  valueFrom:\n                    secretKeyRef:\n                      key: cos-key\n                      name: cos-access\n                - name: COS_SECRET\n                  valueFrom:\n                    secretKeyRef:\n                      key: cos-secret\n                      name: cos-access\n              image: quay.io/ibmdpdev/kfp-oc:2.5.1-py310\n              imagePullPolicy: Always\n          params:\n            - name: wow-so-cool-Output\n            - name: content\n            - name: hash_cpu\n            - name: input_path\n            - name: max_files\n            - name: output_path\n            - name: print_tmout\n            - name: processor_cpu\n            - name: ok-great-Output\n            - name: wait_ready_retries\n            - name: wait_ready_tmout\n          metadata:\n            labels:\n              pipelines.kubeflow.org/cache_enabled: "true"\n            annotations:\n              pipelines.kubeflow.org/component_spec_digest: \'{"name": "Execute ray jobs",\n                "outputs": [], "version": "Execute ray\n                jobs@sha256=bbf2878b3121c17550fbf97e668e66f7c733112b15ba468dbbdfbe942fb5f36a"}\'\n              pipelines.kubeflow.org/max_cache_staleness: P0D\n    finally:\n      - name: cleanup-ray-cluster\n        params:\n          - name: name\n            value: $(params.name)\n        taskSpec:\n          steps:\n            - name: main\n              args:\n                - --name\n                - $(inputs.params.name)\n              command:\n                - sh\n                - -ec\n                - |\n                  program_path=$(mktemp)\n                  printf "%s" "$0" \u003e "$program_path"\n                  python3 -u "$program_path" "$@"\n                - \u003e\n                  def cleanup_ray_cluster(\n                          name,  # name of Ray cluster\n                  ):\n                      # Required imports\n                      import os\n                      import sys\n                      from codeflare_sdk.cluster.auth import TokenAuthentication\n                      from codeflare_sdk.cluster.cluster import Cluster, ClusterConfiguration\n\n                      # get current namespace\n                      ns = os.getenv("NAMESPACE", "default")\n                      # change the current directory to ensure that we can write\n                      os.chdir("/tmp")\n                      print(f"Executing in namespace {ns}, current working directory is {os.getcwd()}")\n\n                      # Create authentication object for oc user permissions\n                      with open("/var/run/secrets/kubernetes.io/serviceaccount/token", "r") as file:\n                          token = file.read().rstrip()\n                      auth = TokenAuthentication(token=token, server="https://kubernetes.default:443", skip_tls=True)\n                      try:\n                          auth.login()\n                      except Exception as e:\n                          print(f"Failed to log into openshift cluster, error {e}. Please check token/server values provided")\n                          sys.exit(1)\n                      print("successfully logged in")\n                      # Create and configure our cluster object (and appwrapper)\n                      cluster = Cluster(\n                          ClusterConfiguration(\n                              name=name,\n                              namespace=ns,\n                          )\n                      )\n                      print(f"Configuration for Ray cluster {name} in namespace {ns} is created")\n                      # delete cluster\n                      print("All done. Cleaning up")\n                      try:\n                          cluster.down()\n                      except Exception as e:\n                          print(f"Failed to down the Ray cluster, error {e}. Please check that the {name} appwrapper is removed")\n\n                  import argparse\n\n                  _parser = argparse.ArgumentParser(prog=\'Cleanup ray cluster\', description=\'\')\n\n                  _parser.add_argument("--name", dest="name", type=str, required=True, default=argparse.SUPPRESS)\n\n                  _parsed_args = vars(_parser.parse_args())\n\n\n                  _outputs = cleanup_ray_cluster(**_parsed_args)\n              env:\n                - name: NAMESPACE\n                  valueFrom:\n                    fieldRef:\n                      fieldPath: metadata.namespace\n              image: quay.io/ibmdpdev/kfp-oc:2.5.1-py310\n              imagePullPolicy: Always\n          params:\n            - name: name\n          metadata:\n            labels:\n              pipelines.kubeflow.org/cache_enabled: "true"\n            annotations:\n              pipelines.kubeflow.org/component_spec_digest: \'{"name": "Cleanup ray cluster",\n                "outputs": [], "version": "Cleanup ray\n                cluster@sha256=d0289f79abcf5240c250d7b8cffead358d6731a59c31c42b662653591da301a1"}\'\n  podTemplate:\n    imagePullSecrets:\n      - name: quay\n',
};
